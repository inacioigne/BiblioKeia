{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore\n",
    "from rdflib import Graph, Namespace, URIRef\n",
    "\n",
    "from xml.dom.minidom import parse\n",
    "import xml.etree.ElementTree as etree\n",
    "from Marc_to_Bibframe.Marc.marcWork import MarcWork\n",
    "from Marc_to_Bibframe.Marc.marcInstance import MarcInstance\n",
    "from Marc_to_Bibframe.Marc.marcItems import MarcItems\n",
    "from Marc_to_Bibframe.Work.work import Work\n",
    "from Marc_to_Bibframe.Instance.instance import Instance\n",
    "\n",
    "import pysolr\n",
    "from Solr.solr import create_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JENA\n",
    "store = SPARQLUpdateStore(update_endpoint='http://localhost:3030/bibframe/update')\n",
    "query_endpoint = 'http://localhost:3030/bibframe/query'\n",
    "update_endpoint = 'http://localhost:3030/bibframe/update'\n",
    "store.open((query_endpoint, update_endpoint))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"zkConnected\":null,\\n    \"status\":0,\\n    \"QTime\":3,\\n    \"params\":{\\n      \"q\":\"{!lucene}*:*\",\\n      \"distrib\":\"false\",\\n      \"df\":\"_text_\",\\n      \"rows\":\"10\",\\n      \"echoParams\":\"all\",\\n      \"rid\":\"localhost-3\"}},\\n  \"status\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLR\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/search/', timeout=10)\n",
    "solr.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Graph(nt, bf, count ):\n",
    "    G1 = \"PREFIX bk: <http://bibliokeia.com/bibframe/\"+bf+\"\"\"/>\n",
    "    PREFIX bf: <http://id.loc.gov/ontologies/bibframe/> \n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX bflc: <http://id.loc.gov/ontologies/bflc/>\n",
    "    PREFIX madsrdf: <http://www.loc.gov/mads/rdf/v1#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "    INSERT DATA {\n",
    "        GRAPH bk:\"\"\"\n",
    "\n",
    "    G2 = \" {\"\n",
    "\n",
    "    G3 = \"\"\"}\n",
    "    }\"\"\"\n",
    "\n",
    "    G = G1+str(count)+\" { \\n\"+nt+\"}}\"\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#date, Converter=<function parse_date at 0x000002EDBBB2CEE0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\inaci\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"c:\\Users\\inaci\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\isodate\\isodates.py\", line 201, in parse_date\n",
      "    return date(sign * int(groups['year']),\n",
      "ValueError: year 0 is out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Computer programming in quantitative biology\n",
      "1\n",
      "Using PC DOS\n",
      "2\n",
      "Estruturas de dados\n",
      "3\n",
      "Programacion en Pascal\n",
      "4\n",
      "CGI programming with Perl\n",
      "5\n",
      "Banco de dados orientado a objeto\n",
      "6\n",
      "Diseño de sistemas de computacion\n",
      "7\n",
      "Tecnologia da informação\n",
      "8\n",
      "Programação Linear com aplicações em microcomputadores\n",
      "9\n",
      "Windows 3.1 helpdesk\n",
      "10\n",
      "Study and compilation of computer languages\n",
      "11\n",
      "CLIPPER 5.0\n",
      "12\n",
      "Effective use of ans cobol computer programming language\n",
      "13\n",
      "Programação estruturada com estudos de casos em Pascal\n",
      "14\n",
      "Aprendendo Delphi 3.0\n",
      "15\n",
      "Aprendendo Delphi 2.0\n",
      "16\n",
      "XML como programar\n",
      "17\n",
      "A simulação da capacidade de suporte para populações agrícolas nos trópicos úmidos\n",
      "18\n",
      "PHP 4\n"
     ]
    }
   ],
   "source": [
    "def Upadate(path_marc, count, shelf):\n",
    "    \n",
    "    marc_file = parse(path_marc)\n",
    "    records = marc_file.getElementsByTagName('record')\n",
    "\n",
    "    docs = list()\n",
    "    for record in records:\n",
    "        \n",
    "        marcxml = etree.fromstring(record.toxml())\n",
    "        workMarc = MarcWork(marcxml)\n",
    "        instanceMarc = MarcInstance(marcxml)\n",
    "        itemsMarc = MarcItems(marcxml)\n",
    "        print(records.index(record))\n",
    "        print(workMarc.Title().get('title'))\n",
    "\n",
    "        #SOLR\n",
    "        doc = create_doc(workMarc, instanceMarc, itemsMarc, 'Livro', shelf, count)\n",
    "        docs.append(doc)\n",
    "\n",
    "        #JENA\n",
    "        BFwork = URIRef(f\"http://bibliokeia.com/bibframe/work/{count}\") \n",
    "        BFinstance = URIRef(f\"http://bibliokeia.com/bibframe/instance/{count}\")\n",
    "        #Work\n",
    "        work = Work(count, workMarc, BFwork, BFinstance)\n",
    "        work.serialize(f'out/E1/P5/works/{count}.ttl', format='turtle')\n",
    "        nt = work.serialize(format='nt')\n",
    "        W = Make_Graph(nt, \"work\", count)\n",
    "        #store.update(W)\n",
    "        #Instance\n",
    "        instance = Instance(count, workMarc, instanceMarc, itemsMarc, BFwork, BFinstance, shelf)\n",
    "        i = instance.get('instance')\n",
    "        #i.serialize(f'out/E1/P2/instances/{count}.ttl', format='turtle')\n",
    "        i_nt = i.serialize(format='nt')\n",
    "        I = Make_Graph(i_nt, \"instance\", count)\n",
    "        #store.update(I)\n",
    "        #Items\n",
    "        items = instance.get('items')\n",
    "        for item, register in items:\n",
    "            #item.serialize(f'out/E1/P3/items/{register}.ttl', format='turtle')\n",
    "            item_nt = item.serialize(format='nt')\n",
    "            Item = Make_Graph(item_nt, \"item\", register)\n",
    "            #store.update(Item)\n",
    "\n",
    "            \n",
    "        count += 1\n",
    "\n",
    "path_marc = r'Input/E1/P5/koha.xml'\n",
    "count = 86\n",
    "Upadate(path_marc, count, \"E1.P5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"status\":0,\\n    \"QTime\":379}}\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solr.add(docs, commit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://id.loc.gov/vocabulary/languages/ po does not look like a valid URI, trying to serialize this will break.\n"
     ]
    }
   ],
   "source": [
    "path_marc = r'Input/E1/P5/koha.xml'\n",
    "marc_file = parse(path_marc)\n",
    "records = marc_file.getElementsByTagName('record')\n",
    "\n",
    "count = 16\n",
    "record = records[count]\n",
    "marcxml = etree.fromstring(record.toxml())\n",
    "workMarc = MarcWork(marcxml)\n",
    "instanceMarc = MarcInstance(marcxml)\n",
    "itemsMarc = MarcItems(marcxml)\n",
    "BFwork = URIRef(f\"http://bibliokeia.com/bibframe/work/{count}\") \n",
    "BFinstance = URIRef(f\"http://bibliokeia.com/bibframe/instance/{count}\")\n",
    "work = Work(count, workMarc, BFwork, BFinstance)\n",
    "instance = Instance(count, workMarc, instanceMarc, itemsMarc, BFwork, BFinstance, 'E1.P3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' po'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workMarc.Language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20100452003     rsba           01 1 por '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workMarc.tag008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'98-0278'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '98-0278 '\n",
    "x.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ne84daf5ad74a41efbade85675acd9138 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse('cli/Out/works/14649397.bibframe.rdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5df21a170a08fe7c24b5b1091267edae5bad3984f1116f28e957af7dd8f192dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
