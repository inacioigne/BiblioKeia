{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore, SPARQLStore\n",
    "from rdflib import Graph, Namespace, URIRef\n",
    "\n",
    "from xml.dom.minidom import parse\n",
    "import xml.etree.ElementTree as etree\n",
    "from Marc_to_Bibframe.Marc.marcWork import MarcWork\n",
    "from Marc_to_Bibframe.Marc.marcInstance import MarcInstance\n",
    "from Marc_to_Bibframe.Marc.marcItems import MarcItems\n",
    "from Marc_to_Bibframe.Work.work import Work\n",
    "from Marc_to_Bibframe.Instance.instance import Instance\n",
    "\n",
    "import pysolr\n",
    "from Solr.solr import create_doc\n",
    "from Jena.jena import create_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JENA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JENA\n",
    "store = SPARQLUpdateStore(update_endpoint='http://localhost:3030/bibframe/update')\n",
    "query_endpoint = 'http://localhost:3030/bibframe/query'\n",
    "update_endpoint = 'http://localhost:3030/bibframe/update'\n",
    "store.open((query_endpoint, update_endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELETE ALL GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all Named Graph\n",
    "\n",
    "d = \"\"\"DELETE { graph ?g { ?s ?p ?o } } \n",
    "\n",
    "WHERE {\n",
    "\n",
    "graph ?g {?s ?p ?o.}\n",
    "\n",
    "}\"\"\"\n",
    "\n",
    "store.update(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"zkConnected\":null,\\n    \"status\":0,\\n    \"QTime\":50,\\n    \"params\":{\\n      \"q\":\"{!lucene}*:*\",\\n      \"distrib\":\"false\",\\n      \"df\":\"_text_\",\\n      \"rows\":\"10\",\\n      \"echoParams\":\"all\",\\n      \"rid\":\"localhost-5\"}},\\n  \"status\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLR\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/search/', timeout=10)\n",
    "solr.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Graph(nt, bf, count ):\n",
    "    G1 = \"PREFIX bk: <http://bibliokeia.com/bibframe/\"+bf+\"\"\"/>\n",
    "    PREFIX bf: <http://id.loc.gov/ontologies/bibframe/> \n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX bflc: <http://id.loc.gov/ontologies/bflc/>\n",
    "    PREFIX madsrdf: <http://www.loc.gov/mads/rdf/v1#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "    INSERT DATA {\n",
    "        GRAPH bk:\"\"\"\n",
    "\n",
    "    G2 = \" {\"\n",
    "\n",
    "    G3 = \"\"\"}\n",
    "    }\"\"\"\n",
    "\n",
    "    G = G1+str(count)+\" { \\n\"+nt+\"}}\"\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Upadate(path_marc, count, shelf, out):\n",
    "    \n",
    "    marc_file = parse(path_marc)\n",
    "    records = marc_file.getElementsByTagName('record')\n",
    "\n",
    "    docs = list()\n",
    "    for record in records:\n",
    "        \n",
    "        marcxml = etree.fromstring(record.toxml())\n",
    "        workMarc = MarcWork(marcxml)\n",
    "        instanceMarc = MarcInstance(marcxml)\n",
    "        itemsMarc = MarcItems(marcxml)\n",
    "        print(count)\n",
    "        print(workMarc.Title().get('title'))\n",
    "\n",
    "        #SOLR\n",
    "        doc = create_doc(workMarc, instanceMarc, itemsMarc, 'Livro', shelf, count)\n",
    "        docs.append(doc)\n",
    "\n",
    "        #JENA\n",
    "        #create_graph(count, workMarc, instanceMarc, itemsMarc, shelf)\n",
    " \n",
    "\n",
    "        count += 1\n",
    "    solr.add(docs, commit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpadateSolr(path_marc, count, shelf, out):\n",
    "    \n",
    "    marc_file = parse(path_marc)\n",
    "    records = marc_file.getElementsByTagName('record')\n",
    "\n",
    "    docs = list()\n",
    "    for record in records:\n",
    "        \n",
    "        marcxml = etree.fromstring(record.toxml())\n",
    "        workMarc = MarcWork(marcxml)\n",
    "        instanceMarc = MarcInstance(marcxml)\n",
    "        itemsMarc = MarcItems(marcxml)\n",
    "        print(count)\n",
    "        print(workMarc.Title().get('title'))\n",
    "\n",
    "        #SOLR\n",
    "        doc = create_doc(workMarc, instanceMarc, itemsMarc, 'Livro', shelf, count)\n",
    "        docs.append(doc)\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    solr.add(docs, commit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 20\n",
    "e = '1'\n",
    "p = '2'\n",
    "out = f'E{e}/P{p}'\n",
    "path_marc = f'Input/{out}/koha.xml'\n",
    "\n",
    "UpadateSolr(path_marc, count, f\"E{e}.P{p}\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpadateJena(path_marc, count, shelf, out):\n",
    "    \n",
    "    marc_file = parse(path_marc)\n",
    "    records = marc_file.getElementsByTagName('record')\n",
    "\n",
    "    docs = list()\n",
    "    for record in records:\n",
    "        \n",
    "        marcxml = etree.fromstring(record.toxml())\n",
    "        workMarc = MarcWork(marcxml)\n",
    "        instanceMarc = MarcInstance(marcxml)\n",
    "        itemsMarc = MarcItems(marcxml)\n",
    "        print(count)\n",
    "        print(workMarc.Title().get('title'))\n",
    "\n",
    "        #JENA\n",
    "        create_graph(count, workMarc, instanceMarc, itemsMarc, shelf)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Resumos\n",
      "21\n",
      "Resumos\n",
      "22\n",
      "Pesquisa científica e tecnológica em saúde\n",
      "23\n",
      "Pesquisas recentes em energia, meio ambiente e tecnologia\n",
      "24\n",
      "Iniciação à pesquisa científica\n",
      "25\n",
      "<1º >Seminário de Ciências da Fiube\n",
      "26\n",
      "Encontro sobre o programa de pesquisas para o trópico úmido.\n",
      "27\n",
      "A pesquisa no Brasil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#date, Converter=<function parse_date at 0x0000025BF6578790>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuário\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"c:\\Users\\Usuário\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\isodate\\isodates.py\", line 201, in parse_date\n",
      "    return date(sign * int(groups['year']),\n",
      "ValueError: year 0 is out of range\n",
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#date, Converter=<function parse_date at 0x0000025BF6578790>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuário\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"c:\\Users\\Usuário\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\isodate\\isodates.py\", line 201, in parse_date\n",
      "    return date(sign * int(groups['year']),\n",
      "ValueError: year 0 is out of range\n",
      "Failed to convert Literal lexical form to value. Datatype=http://www.w3.org/2001/XMLSchema#date, Converter=<function parse_date at 0x0000025BF6578790>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Usuário\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\rdflib\\term.py\", line 2084, in _castLexicalToPython\n",
      "    return conv_func(lexical)  # type: ignore[arg-type]\n",
      "  File \"c:\\Users\\Usuário\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\isodate\\isodates.py\", line 201, in parse_date\n",
      "    return date(sign * int(groups['year']),\n",
      "ValueError: year 0 is out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "Resumos do XVII Seminário de Iniciação Científica da UFPA\n",
      "29\n",
      "FADESP, Fundação de Amaparo e Desenvolvimento da Pesquisa, Belém-Pará.\n",
      "30\n",
      "Manual de normas para publicações técnico-científicas\n",
      "31\n",
      "Manual do autor\n",
      "32\n",
      "Metodos e tecnicas de pesquisa aplicados a administração\n",
      "33\n",
      "A estatística na pesquisa científica\n",
      "34\n",
      "Prioridades da pesquisa do CIFOR\n",
      "35\n",
      "Matemática e estatística na análise de experimentos e no melhoramento genético\n",
      "36\n",
      "Relatório de atividades 2011-2013\n",
      "37\n",
      "Seminário pesquisa tecnológica\n",
      "38\n",
      "Pesquisa científica\n",
      "39\n",
      "Pesquisa operacional\n",
      "40\n",
      "Ciência, tecnologia e inovação para um Brasil competitivo\n",
      "41\n",
      "Os 40 anos da fundação Ford no Brasil\n",
      "42\n",
      "Orçamento da União para ciência e tecnologia, 1980\n",
      "43\n",
      "Guia de fontes de financiamento à ciência & tecnologia\n",
      "44\n",
      "Guia de fontes de financiamento à ciência & tecnologia\n",
      "45\n",
      "Avaliação e fomento de C&T no Brasil\n",
      "46\n",
      "Recherches de I'RD au Brésil depuis 1998\n",
      "47\n",
      "Setor produtivo estatal\n"
     ]
    }
   ],
   "source": [
    "count = 20\n",
    "e = '1'\n",
    "p = '2'\n",
    "out = f'E{e}/P{p}'\n",
    "path_marc = f'Input/{out}/koha.xml'\n",
    "\n",
    "UpadateJena(path_marc, count, f\"E{e}.P{p}\", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c803f0ee3b2b2cd03f94fb28d6f360d094e6843888122798203f226e128b66e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
