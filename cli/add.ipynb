{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore\n",
    "from rdflib import Graph, Namespace, URIRef\n",
    "\n",
    "from xml.dom.minidom import parse\n",
    "import xml.etree.ElementTree as etree\n",
    "from Marc_to_Bibframe.Marc.marcWork import MarcWork\n",
    "from Marc_to_Bibframe.Marc.marcInstance import MarcInstance\n",
    "from Marc_to_Bibframe.Marc.marcItems import MarcItems\n",
    "from Marc_to_Bibframe.Work.work import Work\n",
    "from Marc_to_Bibframe.Instance.instance import Instance\n",
    "\n",
    "import pysolr\n",
    "from Solr.solr import create_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JENA\n",
    "store = SPARQLUpdateStore(update_endpoint='http://localhost:3030/bibframe/update')\n",
    "query_endpoint = 'http://localhost:3030/bibframe/query'\n",
    "update_endpoint = 'http://localhost:3030/bibframe/update'\n",
    "store.open((query_endpoint, update_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"zkConnected\":null,\\n    \"status\":0,\\n    \"QTime\":18,\\n    \"params\":{\\n      \"q\":\"{!lucene}*:*\",\\n      \"distrib\":\"false\",\\n      \"df\":\"_text_\",\\n      \"rows\":\"10\",\\n      \"echoParams\":\"all\",\\n      \"rid\":\"localhost-1\"}},\\n  \"status\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLR\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/search/', timeout=10)\n",
    "solr.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Graph(nt, bf, count ):\n",
    "    G1 = \"PREFIX bk: <http://bibliokeia.com/bibframe/\"+bf+\"\"\"/>\n",
    "    PREFIX bf: <http://id.loc.gov/ontologies/bibframe/> \n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX bflc: <http://id.loc.gov/ontologies/bflc/>\n",
    "    PREFIX madsrdf: <http://www.loc.gov/mads/rdf/v1#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "    INSERT DATA {\n",
    "        GRAPH bk:\"\"\"\n",
    "\n",
    "    G2 = \" {\"\n",
    "\n",
    "    G3 = \"\"\"}\n",
    "    }\"\"\"\n",
    "\n",
    "    G = G1+str(count)+\" { \\n\"+nt+\"}}\"\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Upadate(path_marc, count, shelf, out):\n",
    "    \n",
    "    marc_file = parse(path_marc)\n",
    "    records = marc_file.getElementsByTagName('record')\n",
    "\n",
    "    docs = list()\n",
    "    for record in records:\n",
    "        \n",
    "        marcxml = etree.fromstring(record.toxml())\n",
    "        workMarc = MarcWork(marcxml)\n",
    "        instanceMarc = MarcInstance(marcxml)\n",
    "        itemsMarc = MarcItems(marcxml)\n",
    "        print(records.index(record))\n",
    "        print(workMarc.Title().get('title'))\n",
    "\n",
    "        #SOLR\n",
    "        doc = create_doc(workMarc, instanceMarc, itemsMarc, 'Livro', shelf, count)\n",
    "        docs.append(doc)\n",
    "\n",
    "        # #JENA\n",
    "        # BFwork = URIRef(f\"http://bibliokeia.com/bibframe/work/{count}\") \n",
    "        # BFinstance = URIRef(f\"http://bibliokeia.com/bibframe/instance/{count}\")\n",
    "        # #Work\n",
    "        # work = Work(count, workMarc, BFwork, BFinstance)\n",
    "        # work.serialize(f'out/{out}/works/{count}.ttl', format='turtle')\n",
    "        # nt = work.serialize(format='nt')\n",
    "        # W = Make_Graph(nt, \"work\", count)\n",
    "        # store.update(W)\n",
    "        # #Instance\n",
    "        # instance = Instance(count, workMarc, instanceMarc, itemsMarc, BFwork, BFinstance, shelf)\n",
    "        # i = instance.get('instance')\n",
    "        # i.serialize(f'out/{out}/instances/{count}.ttl', format='turtle')\n",
    "        # i_nt = i.serialize(format='nt')\n",
    "        # I = Make_Graph(i_nt, \"instance\", count)\n",
    "        # store.update(I)\n",
    "        # #Items\n",
    "        # items = instance.get('items')\n",
    "        # for item, register in items:\n",
    "        #     item.serialize(f'out/{out}/items/{register}.ttl', format='turtle')\n",
    "        #     item_nt = item.serialize(format='nt')\n",
    "        #     Item = Make_Graph(item_nt, \"item\", register)\n",
    "        #     store.update(Item)\n",
    "\n",
    "        count += 1\n",
    "    solr.add(docs, commit=True)\n",
    "\n",
    "E = 'E1'\n",
    "P = 'P1'\n",
    "\n",
    "out = 'E2/P1'\n",
    "path_marc = f'Input/{out}/koha.xml'\n",
    "count = 105\n",
    "Upadate(path_marc, count, \"E2.P1\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpadateSolr(path_marc, count, shelf, out):\n",
    "    \n",
    "    marc_file = parse(path_marc)\n",
    "    records = marc_file.getElementsByTagName('record')\n",
    "\n",
    "    docs = list()\n",
    "    for record in records:\n",
    "        \n",
    "        marcxml = etree.fromstring(record.toxml())\n",
    "        workMarc = MarcWork(marcxml)\n",
    "        instanceMarc = MarcInstance(marcxml)\n",
    "        itemsMarc = MarcItems(marcxml)\n",
    "        print(records.index(record))\n",
    "        print(workMarc.Title().get('title'))\n",
    "\n",
    "        #SOLR\n",
    "        doc = create_doc(workMarc, instanceMarc, itemsMarc, 'Livro', shelf, count)\n",
    "        docs.append(doc)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Conjecturas e refutações\n",
      "1\n",
      "Os donos da paisagem\n",
      "2\n",
      "Cooperação Brasil-França\n",
      "3\n",
      "<I=     1> Bienal de Pesquisa da Fundação Oswaldo Cruz, 7 a 11 de dezembro de 1998.\n",
      "4\n",
      "Contribuição da pós-graduação brasileira para o desenvolvimento sustentável\n",
      "5\n",
      "FAPESP\n",
      "6\n",
      "Para uma história da FAPESP\n",
      "7\n",
      "Relatório de atividades 2003-2008\n",
      "8\n",
      "V Jornada científica de pos-graduação da FIOCRUZ\n",
      "9\n",
      "Anais\n",
      "10\n",
      "Anais\n",
      "11\n",
      "Relatório de atividades 2007\n",
      "12\n",
      "Resumos\n",
      "13\n",
      "Resumos\n",
      "14\n",
      "Resumos\n",
      "15\n",
      "Resumos\n",
      "16\n",
      "Resumos\n",
      "17\n",
      "Relatório de atividades 2010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"status\":0,\\n    \"QTime\":1244}}\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 1\n",
    "e = '1'\n",
    "p = '1'\n",
    "out = f'E{e}/P{p}'\n",
    "path_marc = f'Input/{out}/koha.xml'\n",
    "\n",
    "docs = UpadateSolr(path_marc, count, f\"E{e}.P{p}\", out)\n",
    "solr.add(docs, commit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'call': '001 P831c',\n",
       " 'shelf': 'E1.P1',\n",
       " 'title': 'Conjecturas e refutações',\n",
       " 'responsibilities': 'Karl R. Popper; tradução de Sérgio Bath.',\n",
       " 'place': 'Brasília',\n",
       " 'publisher': 'Ed. Universidade de Brasília',\n",
       " 'subject': ['Ciência--Metodologia', 'Teoria do conhecimento'],\n",
       " 'type': 'Livro',\n",
       " 'items': ['01-0519'],\n",
       " 'author': 'Popper, Karl Raimund',\n",
       " 'serie': 'Pensamento científico ; n. 1',\n",
       " 'year': '1982'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' po'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workMarc.Language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominando o PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "print(workMarc.Title().get('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Ne84daf5ad74a41efbade85675acd9138 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse('cli/Out/works/14649397.bibframe.rdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c803f0ee3b2b2cd03f94fb28d6f360d094e6843888122798203f226e128b66e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
