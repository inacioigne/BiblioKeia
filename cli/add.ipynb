{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore, SPARQLStore\n",
    "from rdflib import Graph, Namespace, URIRef\n",
    "\n",
    "from xml.dom.minidom import parse\n",
    "import xml.etree.ElementTree as etree\n",
    "from Marc_to_Bibframe.Marc.marcWork import MarcWork\n",
    "from Marc_to_Bibframe.Marc.marcInstance import MarcInstance\n",
    "from Marc_to_Bibframe.Marc.marcItems import MarcItems\n",
    "from Marc_to_Bibframe.Work.work import Work\n",
    "from Marc_to_Bibframe.Instance.instance import Instance\n",
    "\n",
    "import pysolr\n",
    "from Solr.solr import create_doc\n",
    "from Jena_cli.jena import UpadateJena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELETE ALL GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = SPARQLUpdateStore(update_endpoint='http://localhost:3030/bibframe/update')\n",
    "query_endpoint = 'http://localhost:3030/bibframe/query'\n",
    "update_endpoint = 'http://localhost:3030/bibframe/update'\n",
    "store.open((query_endpoint, update_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all Named Graph\n",
    "\n",
    "d = \"\"\"DELETE { graph ?g { ?s ?p ?o } } \n",
    "\n",
    "WHERE {\n",
    "\n",
    "graph ?g {?s ?p ?o.}\n",
    "\n",
    "}\"\"\"\n",
    "\n",
    "store.update(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"zkConnected\":null,\\n    \"status\":0,\\n    \"QTime\":6,\\n    \"params\":{\\n      \"q\":\"{!lucene}*:*\",\\n      \"distrib\":\"false\",\\n      \"df\":\"_text_\",\\n      \"rows\":\"10\",\\n      \"echoParams\":\"all\",\\n      \"rid\":\"localhost-1\"}},\\n  \"status\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLR\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/search/', timeout=10)\n",
    "solr.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpadateSolr(path_marc, count, shelf):\n",
    "\n",
    "    #SOLR\n",
    "    #solr = pysolr.Solr('http://localhost:8983/solr/search/', timeout=10)\n",
    "    #solr.ping()\n",
    "    \n",
    "    marc_file = parse(path_marc)\n",
    "    records = marc_file.getElementsByTagName('record')\n",
    "\n",
    "    docs = list()\n",
    "    for record in records:\n",
    "        \n",
    "        marcxml = etree.fromstring(record.toxml())\n",
    "        workMarc = MarcWork(marcxml)\n",
    "        instanceMarc = MarcInstance(marcxml)\n",
    "        itemsMarc = MarcItems(marcxml)\n",
    "        print(count)\n",
    "        print(workMarc.Title().get('title'))\n",
    "\n",
    "        #SOLR\n",
    "        doc = create_doc(workMarc, instanceMarc, itemsMarc, 'Livro', shelf, count)\n",
    "        docs.append(doc)\n",
    "        \n",
    "        count += 1\n",
    "    return docs, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "A conquista do êxito\n",
      "379\n",
      "O encontro com o eu interior\n",
      "380\n",
      "Palavras que levam ao sucesso\n",
      "381\n",
      "Modernos métodos de venda\n",
      "382\n",
      "Mais psicologia, melhores negócios\n",
      "383\n",
      "Conheça melhor a si mesmo e às pessoas com quem trata\n",
      "384\n",
      "O comércio através dos tempos\n",
      "385\n",
      "Sucesso nas relações humanas\n",
      "386\n",
      "Psicologia industrial\n",
      "387\n",
      "Probability and the logic of rational belief\n",
      "388\n",
      "Lógica elementar\n",
      "389\n",
      "Escolha e acaso\n",
      "390\n",
      "Lógica e existência\n",
      "391\n",
      "Tractatus logico-philosophicus\n",
      "392\n",
      "Lógica\n",
      "393\n",
      "Ética e saúde\n",
      "394\n",
      "Patentes, transgênicos e clonagem\n",
      "395\n",
      "As regras morais e a ética\n",
      "396\n",
      "Tongues of conscience\n",
      "397\n",
      "Capacitação para comitês de ética em pesquisa.\n",
      "398\n",
      "Ética social\n",
      "399\n",
      "Ethics, religion and, biodiversity\n",
      "400\n",
      "Mito e pensamento entre os gregos\n",
      "401\n",
      "Horizonte e complementariedade\n",
      "402\n",
      "Gênese, significado e ensino da filosofia no século XII\n",
      "403\n",
      "A filosofia contemporânea ocidental\n",
      "404\n",
      "As idéias de Bertrand Russell\n",
      "405\n",
      "Bachelard: raison et imagination = Bachelard: razão e imaginação\n"
     ]
    }
   ],
   "source": [
    "count = 378\n",
    "e = '3'\n",
    "p = '5'\n",
    "out = f'E{e}/P{p}'\n",
    "path_marc = f'Input/{out}/koha.xml'\n",
    "\n",
    "docs, _ = UpadateSolr(path_marc, count, f\"E{e}.P{p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"status\":0,\\n    \"QTime\":348}}\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solr = pysolr.Solr('http://localhost:8983/solr/search/', timeout=10)\n",
    "solr.add(docs, commit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT LOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "solr_docs = list()\n",
    "for e in range(1, 3):\n",
    "    for p in range(1,6):\n",
    "        path_marc = f'Input/E{e}/P{p}/koha.xml'\n",
    "        docs, count  = UpadateSolr(path_marc, count, f\"E{e}.P{p}\")\n",
    "        #solr_docs.append(docs)\n",
    "        solr_docs = solr_docs + docs\n",
    "        #count += 1\n",
    "        #print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"status\":0,\\n    \"QTime\":1736}}\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solr = pysolr.Solr('http://localhost:8983/solr/search/', timeout=10)\n",
    "solr.add(solr_docs, commit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JENA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Conjecturas e refutações\n",
      "2\n",
      "Os donos da paisagem\n",
      "3\n",
      "Cooperação Brasil-França\n",
      "4\n",
      "<I=     1> Bienal de Pesquisa da Fundação Oswaldo Cruz, 7 a 11 de dezembro de 1998.\n",
      "5\n",
      "Contribuição da pós-graduação brasileira para o desenvolvimento sustentável\n",
      "6\n",
      "FAPESP\n",
      "7\n",
      "Para uma história da FAPESP\n",
      "8\n",
      "Relatório de atividades 2003-2008\n",
      "9\n",
      "Relatório de atividades 2007\n",
      "10\n",
      "Relatório de atividades 2010\n",
      "11\n",
      "V Jornada científica de pos-graduação da FIOCRUZ\n",
      "12\n",
      "Anais\n",
      "13\n",
      "Resumos\n",
      "14\n",
      "Anais\n",
      "15\n",
      "Resumos\n",
      "16\n",
      "Resumos\n",
      "17\n",
      "Resumos\n",
      "18\n",
      "Resumos\n",
      "19\n",
      "Congresso de iniciação científica da Universidade Federal do Amazonas\n",
      "20\n",
      "Resumos\n",
      "21\n",
      "Resumos\n",
      "22\n",
      "Pesquisa científica e tecnológica em saúde\n",
      "23\n",
      "Pesquisas recentes em energia, meio ambiente e tecnologia\n",
      "24\n",
      "Iniciação à pesquisa científica\n",
      "25\n",
      "<1º >Seminário de Ciências da Fiube\n",
      "26\n",
      "Encontro sobre o programa de pesquisas para o trópico úmido.\n",
      "27\n",
      "A pesquisa no Brasil\n",
      "28\n",
      "Resumos do XVII Seminário de Iniciação Científica da UFPA\n",
      "29\n",
      "FADESP, Fundação de Amaparo e Desenvolvimento da Pesquisa, Belém-Pará.\n",
      "30\n",
      "Manual de normas para publicações técnico-científicas\n",
      "31\n",
      "Manual do autor\n",
      "32\n",
      "Metodos e tecnicas de pesquisa aplicados a administração\n",
      "33\n",
      "A estatística na pesquisa científica\n",
      "34\n",
      "Prioridades da pesquisa do CIFOR\n",
      "35\n",
      "Matemática e estatística na análise de experimentos e no melhoramento genético\n",
      "36\n",
      "Relatório de atividades 2011-2013\n",
      "37\n",
      "Seminário pesquisa tecnológica\n",
      "38\n",
      "Pesquisa científica\n",
      "39\n",
      "Pesquisa operacional\n",
      "40\n",
      "Ciência, tecnologia e inovação para um Brasil competitivo\n",
      "41\n",
      "Os 40 anos da fundação Ford no Brasil\n",
      "42\n",
      "Orçamento da União para ciência e tecnologia, 1980\n",
      "43\n",
      "Guia de fontes de financiamento à ciência & tecnologia\n",
      "44\n",
      "Guia de fontes de financiamento à ciência & tecnologia\n",
      "45\n",
      "Avaliação e fomento de C&T no Brasil\n",
      "46\n",
      "Recherches de I'RD au Brésil depuis 1998\n",
      "47\n",
      "Setor produtivo estatal\n",
      "48\n",
      "Pesquisas amazônicas\n",
      "49\n",
      "Functional analysis of information networks\n",
      "50\n",
      "Informação e tecnologia\n",
      "51\n",
      "Télématique\n",
      "52\n",
      "Comunicação extensiva e informação em rede\n",
      "53\n",
      "Tecnologias da informação e comunicação\n",
      "54\n",
      "O que os computadores não podem fazer\n",
      "55\n",
      "Introdução à teoria da informação\n",
      "56\n",
      "Informatique de gestion\n",
      "57\n",
      "Informatique de gestion\n",
      "58\n",
      "Computer simulation in human population studies\n",
      "59\n",
      "Multivariate data analysis\n",
      "60\n",
      "Introduccíon al procesamiento de datos\n",
      "61\n",
      "Introduction to data processing\n",
      "62\n",
      "Anais\n",
      "63\n",
      "Méthodologie de constitution d'une base de données d'occupation du sol par télédétection\n",
      "64\n",
      "Ciencia de la computación\n",
      "65\n",
      "The Internet for scientists and engineers\n",
      "66\n",
      "Teoria geral dos sistemas\n",
      "67\n",
      "Análise e projeto de sistemas\n",
      "68\n",
      "Manual de análise de sistemas\n",
      "69\n",
      "Manual de los sistemas de informacion\n",
      "70\n",
      "Micro-ordinateur une solution pour votre gestion\n",
      "71\n",
      "Computadores eletrônicos digitais\n",
      "72\n",
      "Computers, communications and society\n",
      "73\n",
      "Arquitectura de computadores\n",
      "74\n",
      "Segurança\n",
      "75\n",
      "Processamento de dados\n",
      "76\n",
      "Simulação em computador digital\n",
      "77\n",
      "The theory and practice of reliable system design\n",
      "78\n",
      "Desenvolvendo sistemas sem complicação\n",
      "79\n",
      "Introduction to microcomputers and microprocessors\n",
      "80\n",
      "PC\n",
      "81\n",
      "Informatica\n",
      "82\n",
      "Micro computador\n",
      "83\n",
      "Microprocessors and microcomputers\n",
      "84\n",
      "Como cuidar bem do seu micro\n",
      "85\n",
      "Computação analógica\n",
      "86\n",
      "Data structures\n",
      "87\n",
      "Computer programming in quantitative biology\n",
      "88\n",
      "Using PC DOS\n",
      "89\n",
      "Estruturas de dados\n",
      "90\n",
      "Programacion en Pascal\n",
      "91\n",
      "CGI programming with Perl\n",
      "92\n",
      "Banco de dados orientado a objeto\n",
      "93\n",
      "Diseño de sistemas de computacion\n",
      "94\n",
      "Tecnologia da informação\n",
      "95\n",
      "Windows 3.1 helpdesk\n",
      "96\n",
      "Programação Linear com aplicações em microcomputadores\n",
      "97\n",
      "Study and compilation of computer languages\n",
      "98\n",
      "CLIPPER 5.0\n",
      "99\n",
      "Effective use of ans cobol computer programming language\n",
      "100\n",
      "Programação estruturada com estudos de casos em Pascal\n",
      "101\n",
      "Aprendendo Delphi 3.0\n",
      "102\n",
      "Aprendendo Delphi 2.0\n",
      "103\n",
      "XML como programar\n",
      "104\n",
      "A simulação da capacidade de suporte para populações agrícolas nos trópicos úmidos\n",
      "105\n",
      "PHP 4\n",
      "106\n",
      "An introduction to RPG-RPG II programming\n",
      "107\n",
      "Programacion con el lenguaje Cobol\n",
      "108\n",
      "Dominando o PostgreSQL\n",
      "109\n",
      "Study notes in system dynamics.\n",
      "110\n",
      "TURBO PASCAL\n",
      "111\n",
      "FORTH, guia do usuário\n",
      "112\n",
      "Princípios em projetos de programas\n",
      "113\n",
      "Lenguajes de diagramas de flujo\n",
      "114\n",
      "Linguagem PASCAL\n",
      "115\n",
      "A simplified guide to FORTRAN programming\n",
      "116\n",
      "Lingugem C\n",
      "117\n",
      "Biblioteca do programador Clipper 5.01\n",
      "118\n",
      "Delphi 2\n",
      "119\n",
      "Manipulando bancos de dados com Delphi 2\n",
      "120\n",
      "SQL para Delphi 2\n",
      "121\n",
      "Cobol y sus aplicaciones en los negocios\n",
      "122\n",
      "Clipper\n",
      "123\n",
      "Pascal e técnicas de programação\n",
      "124\n",
      "I simpósio brasileiro de linguagens de programação\n",
      "125\n",
      "MUMPS: uma nova abordagem\n",
      "126\n",
      "turbo Pascal\n",
      "127\n",
      "Supercalc\n",
      "128\n",
      "Fortran\n",
      "129\n",
      "Fortran - Monitor\n",
      "130\n",
      "Quattro Pro 2\n",
      "131\n",
      "Desktop publishing com pagemaker IBM PC AT, PS.2 e compatíveis\n",
      "132\n",
      "Macro processors and techniques for portable software\n",
      "133\n",
      "TURBO BASIC\n",
      "134\n",
      "Princípios de sistemas de gerência de bancos de dados distribuídos\n",
      "135\n",
      "Sistemas de gerência de bancos de dados distribuídos\n",
      "136\n",
      "DR DOS 6.0\n",
      "137\n",
      "DR Dos 6.0\n",
      "138\n",
      "Wordstar 4.2\n",
      "139\n",
      "WORDSTAR 5.0 professional\n",
      "140\n",
      "The Microsoft guide to managing memory with DOS 5\n",
      "141\n",
      "Dbase III plus\n",
      "142\n",
      "Wordperfect macros\n",
      "143\n",
      "Word\n",
      "144\n",
      "Novidades do Borland Delphi 3\n",
      "145\n",
      "Storyboard plus\n",
      "146\n",
      "Windows 95\n",
      "147\n",
      "O ABC do MS/DOS\n",
      "148\n",
      "Guia do DOS 5\n",
      "149\n",
      "Harvard graphics\n",
      "150\n",
      "Programação e métodos computacionais\n",
      "151\n",
      "Programação orientada para objeto com Turbo C++\n",
      "152\n",
      "Dynamo user's manual\n",
      "153\n",
      "Quattro Pro para Windows\n",
      "154\n",
      "Clipper em redes\n",
      "155\n",
      "Clipper- Summer' 87\n",
      "156\n",
      "Clipper\n",
      "157\n",
      "Clipper\n",
      "158\n",
      "Clipper 5\n",
      "159\n",
      "77 funções para o Clipper\n",
      "160\n",
      "Norton Utilities 6\n",
      "161\n",
      "PC Tools 7.1\n",
      "162\n",
      "Analise de sistemas orientada para objetos\n",
      "163\n",
      "SigmaPlot 10\n",
      "164\n",
      "CLIPPER compilador dBASE III\n",
      "165\n",
      "QUATTRO\n",
      "166\n",
      "The pc-sig library\n",
      "167\n",
      "dBase II\n",
      "168\n",
      "CLIPPER'87\n",
      "169\n",
      "Software orientado ao objeto\n",
      "170\n",
      "Guia byte para o CD-ROM\n",
      "171\n",
      "Impressão\n",
      "172\n",
      "Como funciona a Internet\n",
      "173\n",
      "Lan\n",
      "174\n",
      "Diagnóstico e solução de problemas\n",
      "175\n",
      "Como implantar e gerenciar Novell Netware\n",
      "176\n",
      "Linking mechanisms for biodiversity information\n",
      "177\n",
      "Modelagem de dados\n",
      "178\n",
      "Disco rígido no PC\n",
      "179\n",
      "Programando em 3 dimensões\n",
      "180\n",
      "Needs and specifications for biodiversity information network\n",
      "181\n",
      "Vampiros extraterrestres na Amazônia\n",
      "182\n",
      "Normas para publicação de trabalhos técnicos-científicos do CPPSE\n",
      "183\n",
      "Manual de walkthroughs\n",
      "184\n",
      "Manual de desenvolvimento de sistemas estruturados\n",
      "185\n",
      "Bioestat\n",
      "186\n",
      "Aide-mémoire d'informatique\n",
      "187\n",
      "Periódicos brasileiros em microformas\n",
      "188\n",
      "Coleção Affonso Penna Junior\n",
      "189\n",
      "Catálogo de obras raras sobre a Amazônia (1800 - 1899)\n",
      "190\n",
      "Catálogo de serviços\n",
      "191\n",
      "Plano anual de trabalho 1994\n",
      "192\n",
      "Educação, ciência e tecnologia\n",
      "193\n",
      "The Brazilian Amazon\n",
      "194\n",
      "Catálogo da coleção Béatrix Reynal\n",
      "195\n",
      "Catálogo de dissertação e teses dos técnicos do incaper\n",
      "196\n",
      "Resumos de teses e dissertações do Projeto Dinâmica Biológica de Fragmentos Florestais\n",
      "197\n",
      "Catálogo de teses e dissertações da Universidade do Amazonas (1952-1985)\n",
      "198\n",
      "Catálogo de teses e dissertações da Universidade do Amazonas (1989 - 1993)\n",
      "199\n",
      "Cem anos de imprensa no Amazonas (1851-1951)\n",
      "200\n",
      "Catálogo de teses e dissertações da Universidade do Amazonas (1986-1988)\n",
      "201\n",
      "World list of scientific periodicals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://id.loc.gov/vocabulary/languages/    does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "Inventário e avaliação da produção técnico-científica sobre migração na Amazônia legal.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\cli\\add.ipynb Célula: 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/inaci/Desktop/BiblioKeia/cli/add.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m path_marc \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput/\u001b[39m\u001b[39m{\u001b[39;00mout\u001b[39m}\u001b[39;00m\u001b[39m/koha.xml\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/inaci/Desktop/BiblioKeia/cli/add.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m shelf \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mE\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m.P\u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/inaci/Desktop/BiblioKeia/cli/add.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m count \u001b[39m=\u001b[39m UpadateJena(path_marc, count, shelf, out)\n",
      "File \u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\cli\\Jena_cli\\jena.py:56\u001b[0m, in \u001b[0;36mUpadateJena\u001b[1;34m(path_marc, count, shelf, out)\u001b[0m\n\u001b[0;32m     54\u001b[0m BFinstance \u001b[39m=\u001b[39m URIRef(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttp://bibliokeia.com/bibframe/instance/\u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[39m#Work\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m work \u001b[39m=\u001b[39m Work(count, workMarc, BFwork, BFinstance)\n\u001b[0;32m     57\u001b[0m \u001b[39m#work.serialize(f'out/{out}/works/{count}.ttl', format='turtle')\u001b[39;00m\n\u001b[0;32m     58\u001b[0m nt \u001b[39m=\u001b[39m work\u001b[39m.\u001b[39mserialize(\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\cli\\Marc_to_Bibframe\\Work\\work.py:42\u001b[0m, in \u001b[0;36mWork\u001b[1;34m(count, workMarc, BFwork, BFinstance)\u001b[0m\n\u001b[0;32m     40\u001b[0m g \u001b[39m=\u001b[39m Language(g, BFwork, workMarc, BF)\n\u001b[0;32m     41\u001b[0m \u001b[39m#Audience\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[39mif\u001b[39;00m workMarc\u001b[39m.\u001b[39;49mAudience():\n\u001b[0;32m     43\u001b[0m     g \u001b[39m=\u001b[39m Audience(g, BFwork, workMarc, BF)\n\u001b[0;32m     44\u001b[0m \u001b[39m#Classification\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\cli\\Marc_to_Bibframe\\Marc\\marcWork.py:65\u001b[0m, in \u001b[0;36mMarcWork.Audience\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m code \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m codes[code]\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for i in range(1,3):\n",
    "    e = i\n",
    "    for p in range(1,6):\n",
    "        out = f'E{e}/P{p}'\n",
    "        path_marc = f'Input/{out}/koha.xml'\n",
    "        shelf = f\"E{e}.P{p}\"\n",
    "        count = UpadateJena(path_marc, count, shelf, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "An introduction to RPG-RPG II programming\n",
      "107\n",
      "Programacion con el lenguaje Cobol\n",
      "108\n",
      "Dominando o PostgreSQL\n",
      "109\n",
      "Study notes in system dynamics.\n",
      "110\n",
      "TURBO PASCAL\n",
      "111\n",
      "FORTH, guia do usuário\n",
      "112\n",
      "Princípios em projetos de programas\n",
      "113\n",
      "Lenguajes de diagramas de flujo\n",
      "114\n",
      "Linguagem PASCAL\n",
      "115\n",
      "A simplified guide to FORTRAN programming\n",
      "116\n",
      "Lingugem C\n",
      "117\n",
      "Biblioteca do programador Clipper 5.01\n",
      "118\n",
      "Delphi 2\n",
      "119\n",
      "Manipulando bancos de dados com Delphi 2\n",
      "120\n",
      "SQL para Delphi 2\n",
      "121\n",
      "Cobol y sus aplicaciones en los negocios\n",
      "122\n",
      "Clipper\n",
      "123\n",
      "Pascal e técnicas de programação\n",
      "124\n",
      "I simpósio brasileiro de linguagens de programação\n",
      "125\n",
      "MUMPS: uma nova abordagem\n",
      "126\n",
      "turbo Pascal\n",
      "127\n",
      "Supercalc\n",
      "128\n",
      "Fortran\n",
      "129\n",
      "Fortran - Monitor\n",
      "130\n",
      "Quattro Pro 2\n",
      "131\n",
      "Desktop publishing com pagemaker IBM PC AT, PS.2 e compatíveis\n",
      "132\n",
      "Macro processors and techniques for portable software\n",
      "133\n",
      "TURBO BASIC\n",
      "134\n",
      "Princípios de sistemas de gerência de bancos de dados distribuídos\n",
      "135\n",
      "Sistemas de gerência de bancos de dados distribuídos\n",
      "136\n",
      "DR DOS 6.0\n",
      "137\n",
      "DR Dos 6.0\n",
      "138\n",
      "Wordstar 4.2\n",
      "139\n",
      "WORDSTAR 5.0 professional\n",
      "140\n",
      "The Microsoft guide to managing memory with DOS 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "http://id.loc.gov/vocabulary/languages/0 p does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "Dbase III plus\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "\"http://id.loc.gov/vocabulary/languages/0 p\" does not look like a valid URI, I cannot serialize this as N3/Turtle. Perhaps you wanted to urlencode it?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\cli\\add.ipynb Célula: 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/inaci/Desktop/BiblioKeia/cli/add.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mE\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m/P\u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/inaci/Desktop/BiblioKeia/cli/add.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m path_marc \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput/\u001b[39m\u001b[39m{\u001b[39;00mout\u001b[39m}\u001b[39;00m\u001b[39m/koha.xml\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/inaci/Desktop/BiblioKeia/cli/add.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m count \u001b[39m=\u001b[39m UpadateJena(path_marc, count, shelf, out)\n",
      "File \u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\cli\\Jena_cli\\jena.py:58\u001b[0m, in \u001b[0;36mUpadateJena\u001b[1;34m(path_marc, count, shelf, out)\u001b[0m\n\u001b[0;32m     56\u001b[0m work \u001b[39m=\u001b[39m Work(count, workMarc, BFwork, BFinstance)\n\u001b[0;32m     57\u001b[0m \u001b[39m#work.serialize(f'out/{out}/works/{count}.ttl', format='turtle')\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m nt \u001b[39m=\u001b[39m work\u001b[39m.\u001b[39;49mserialize(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     59\u001b[0m W \u001b[39m=\u001b[39m Make_Graph(nt, \u001b[39m\"\u001b[39m\u001b[39mwork\u001b[39m\u001b[39m\"\u001b[39m, count)\n\u001b[0;32m     60\u001b[0m store\u001b[39m.\u001b[39mupdate(W)\n",
      "File \u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\rdflib\\graph.py:1186\u001b[0m, in \u001b[0;36mGraph.serialize\u001b[1;34m(self, destination, format, base, encoding, **args)\u001b[0m\n\u001b[0;32m   1184\u001b[0m stream \u001b[39m=\u001b[39m BytesIO()\n\u001b[0;32m   1185\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m     serializer\u001b[39m.\u001b[39mserialize(stream, base\u001b[39m=\u001b[39mbase, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs)\n\u001b[0;32m   1187\u001b[0m     \u001b[39mreturn\u001b[39;00m stream\u001b[39m.\u001b[39mgetvalue()\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1188\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\rdflib\\plugins\\serializers\\nt.py:41\u001b[0m, in \u001b[0;36mNTSerializer.serialize\u001b[1;34m(self, stream, base, encoding, **args)\u001b[0m\n\u001b[0;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     36\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNTSerializer always uses UTF-8 encoding. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGiven encoding was: \u001b[39m\u001b[39m{\u001b[39;00mencoding\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m triple \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore:\n\u001b[1;32m---> 41\u001b[0m     stream\u001b[39m.\u001b[39mwrite(_nt_row(triple)\u001b[39m.\u001b[39mencode())\n",
      "File \u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\rdflib\\plugins\\serializers\\nt.py:63\u001b[0m, in \u001b[0;36m_nt_row\u001b[1;34m(triple)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m .\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m     58\u001b[0m         triple[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn3(),\n\u001b[0;32m     59\u001b[0m         triple[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mn3(),\n\u001b[0;32m     60\u001b[0m         _quoteLiteral(triple[\u001b[39m2\u001b[39m]),\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m .\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (triple[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn3(), triple[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mn3(), triple[\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39;49mn3())\n",
      "File \u001b[1;32mc:\\Users\\inaci\\Desktop\\BiblioKeia\\venv\\lib\\site-packages\\rdflib\\term.py:300\u001b[0m, in \u001b[0;36mURIRef.n3\u001b[1;34m(self, namespace_manager)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[39mThis will do a limited check for valid URIs,\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39messentially just making sure that the string includes no illegal\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m     a prefixed name\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_uri(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m does not look like a valid URI, I cannot serialize this as N3/Turtle. Perhaps you wanted to urlencode it?\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m    303\u001b[0m     )\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m namespace_manager:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m namespace_manager\u001b[39m.\u001b[39mnormalizeUri(\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: \"http://id.loc.gov/vocabulary/languages/0 p\" does not look like a valid URI, I cannot serialize this as N3/Turtle. Perhaps you wanted to urlencode it?"
     ]
    }
   ],
   "source": [
    "e = 2\n",
    "count = 106\n",
    "for p in range(1,6):\n",
    "    out = f'E{e}/P{p}'\n",
    "    path_marc = f'Input/{out}/koha.xml'\n",
    "    count = UpadateJena(path_marc, count, shelf, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5df21a170a08fe7c24b5b1091267edae5bad3984f1116f28e957af7dd8f192dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
